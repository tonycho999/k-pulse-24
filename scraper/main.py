import os
import sys
import json
import urllib.request
import urllib.parse
import requests
from bs4 import BeautifulSoup
from supabase import create_client, Client
from datetime import datetime
from dotenv import load_dotenv
from groq import Groq
from urllib.parse import urljoin  # ì¶”ê°€ë¨: ì£¼ì†Œ ê²°í•©ìš©

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
sys.stdout.reconfigure(encoding='utf-8')

supabase_url = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
supabase_key = os.environ.get("NEXT_PUBLIC_SUPABASE_ANON_KEY")
groq_api_key = os.environ.get("GROQ_API_KEY")
naver_client_id = os.environ.get("NAVER_CLIENT_ID")
naver_client_secret = os.environ.get("NAVER_CLIENT_SECRET")

if not all([supabase_url, supabase_key, groq_api_key, naver_client_id, naver_client_secret]):
    print("âŒ Error: .env í‚¤ í™•ì¸ í•„ìš”")
    sys.exit(1)

supabase: Client = create_client(supabase_url, supabase_key)
groq_client = Groq(api_key=groq_api_key)
AI_MODEL = "llama-3.3-70b-versatile"

SEARCH_KEYWORDS = ["K-POP ì•„ì´ëŒ", "í•œêµ­ ì¸ê¸° ë“œë¼ë§ˆ", "í•œêµ­ ì˜í™” í™”ì œ", "í•œêµ­ ì˜ˆëŠ¥ ë ˆì „ë“œ"]

def get_real_news_image(link):
    """
    ê°•í™”ëœ ì´ë¯¸ì§€ ì¶”ì¶œê¸°: ë©”íƒ€ ë°ì´í„° ë° ë³¸ë¬¸ ë‚´ ê³ í™”ì§ˆ ì´ë¯¸ì§€ íƒìƒ‰
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Referer': 'https://news.naver.com/'
        }
        
        response = requests.get(link, headers=headers, timeout=10)
        if response.status_code != 200: return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        img_url = None

        # 1. og:image ìš°ì„  íƒìƒ‰
        og_image = soup.find('meta', property='og:image')
        if og_image and og_image.get('content'):
            img_url = og_image['content']
            
        # 2. og:imageê°€ ì—†ê±°ë‚˜ ë„¤ì´ë²„ ê¸°ë³¸ ë¡œê³ ì¼ ê²½ìš° ë³¸ë¬¸ íƒìƒ‰
        if not img_url or "static.naver.net" in img_url:
            # ë„¤ì´ë²„ ë‰´ìŠ¤ ë° ì£¼ìš” ì–¸ë¡ ì‚¬ ë³¸ë¬¸ ì´ë¯¸ì§€ ì…€ë ‰í„°
            selectors = ['#dic_area img', '#articleBodyContents img', '.article_kanvas img', '.article_body img', 'article img']
            for selector in selectors:
                img_tag = soup.select_one(selector)
                if img_tag and img_tag.get('src'):
                    img_url = img_tag['src']
                    break
        
        if img_url:
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ì˜ˆ: /img.jpg -> https://news.com/img.jpg)
            img_url = urljoin(link, img_url)
            return img_url

    except Exception as e:
        print(f"âš ï¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return None

def get_naver_api_news(keyword):
    encText = urllib.parse.quote(keyword)
    url = f"https://openapi.naver.com/v1/search/news?query={encText}&display=15&sort=sim"
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", naver_client_id)
    req.add_header("X-Naver-Client-Secret", naver_client_secret)
    
    try:
        res = urllib.request.urlopen(req)
        return json.loads(res.read().decode('utf-8')).get('items', [])
    except: return []

def ai_chief_editor(news_batch):
    news_text = ""
    for idx, item in enumerate(news_batch):
        clean_title = item['title'].replace('<b>', '').replace('</b>', '').replace('&quot;', '"')
        news_text += f"{idx+1}. {clean_title}\n"

    prompt = f"""Role: Chief Editor. Task: Select Top 12. Output JSON strictly. Raw Titles:\n{news_text}"""
    try:
        res = groq_client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model=AI_MODEL,
            response_format={"type": "json_object"}
        )
        return json.loads(res.choices[0].message.content)
    except: return None

def run():
    print(f"=== {datetime.now()} ì‹¤ì „ ì´ë¯¸ì§€ ì¶”ì¶œ ëª¨ë“œ ì‹œì‘ ===")
    all_news = []
    for keyword in SEARCH_KEYWORDS:
        all_news.extend(get_naver_api_news(keyword))
    
    result = ai_chief_editor(all_news)
    if not result: return

    saved_count = 0
    for article in result.get('articles', []):
        idx = article.get('original_title_index', 1) - 1
        if idx < 0 or idx >= len(all_news): idx = 0
        original = all_news[idx]

        # ğŸ“¡ ì‹¤ì œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œë„
        real_img = get_real_news_image(original['link'])
        
        # âŒ ì‹¤íŒ¨ ì‹œì—ë§Œ placeholder ì‚¬ìš© (ì´ë•Œ ë¡œê·¸ë¥¼ ë‚¨ê²¨ í™•ì¸)
        if not real_img:
            print(f"âš ï¸ ì´ë¯¸ì§€ë¥¼ ëª» ì°¾ìŒ: {article['title'][:20]}...")
            real_img = f"https://placehold.co/600x400/111/cyan?text={article.get('artist', 'News').replace(' ', '+')}"
        else:
            print(f"ğŸ“¸ ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ: {real_img[:50]}...")

        try:
            if supabase.table("live_news").select("id").eq("title", article['title']).execute().data: continue
            
            data = {
                "category": article.get('category', 'General'),
                "artist": article.get('artist', 'Trend'),
                "title": article['title'],
                "summary": article['summary'],
                "score": article.get('score', 5),
                "link": original['link'],
                "source": "Naver News",
                "image_url": real_img,
                "reactions": article['reactions'],
                "is_published": True,
                "created_at": datetime.now().isoformat()
            }
            supabase.table("live_news").insert(data).execute()
            saved_count += 1
        except Exception as e: print(f"ğŸ’¾ ì €ì¥ ì—ëŸ¬: {e}")

    print(f"=== ì™„ë£Œ: {saved_count}ê°œ ì—…ë°ì´íŠ¸ë¨ ===")

if __name__ == "__main__":
    run()
