import os
import json
import time
import requests
from supabase import create_client, Client
from dotenv import load_dotenv
from ddgs import DDGS

load_dotenv()

SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

if GOOGLE_API_KEY:
    print(f"ğŸ”‘ API Key ë¡œë“œ ì™„ë£Œ: {GOOGLE_API_KEY[:5]}...")
else:
    print("âŒ API Keyê°€ ì—†ìŠµë‹ˆë‹¤!")

CATEGORIES = {
    "K-Pop": "k-pop latest news trends",
    "K-Drama": "k-drama ratings news",
    "K-Movie": "korean movie box office news",
    "K-Variety": "korean variety show news",
    "K-Culture": "seoul travel food trends"
}

def get_dynamic_model_url():
    print("ğŸ” êµ¬ê¸€ ì„œë²„ì— ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
    list_url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GOOGLE_API_KEY}"
    try:
        response = requests.get(list_url)
        if response.status_code != 200:
            return "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
        data = response.json()
        models = data.get('models', [])
        valid_models = []
        for m in models:
            name = m['name'] 
            methods = m.get('supportedGenerationMethods', [])
            if 'generateContent' in methods and 'flash' in name:
                valid_models.append(name)
        if valid_models:
            best_model = valid_models[-1]
            print(f"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì  ëª¨ë¸ ë°œê²¬: {best_model}")
            return f"https://generativelanguage.googleapis.com/v1beta/{best_model}:generateContent"
        return "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"
    except Exception as e:
        print(f"âŒ ëª¨ë¸ íƒìƒ‰ ì¤‘ ì—ëŸ¬: {e}")
        return "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

CURRENT_MODEL_URL = get_dynamic_model_url()

def search_web(keyword):
    print(f"ğŸ” [Search] '{keyword}' ê²€ìƒ‰ ì¤‘...")
    results = []
    try:
        with DDGS() as ddgs:
            ddg_results = list(ddgs.news(query=keyword, region="kr-kr", safesearch="off", max_results=10))
            if not ddg_results:
                time.sleep(1)
                ddg_results = list(ddgs.text(query=keyword, region="kr-kr", max_results=5))

            for r in ddg_results:
                title = r.get('title', '')
                body = r.get('body', r.get('snippet', ''))
                link = r.get('url', r.get('href', ''))
                image = r.get('image', r.get('thumbnail', ''))

                if title and body:
                    results.append(f"ì œëª©: {title}\në‚´ìš©: {body}\në§í¬: {link}\nì´ë¯¸ì§€: {image}")
    except Exception as e:
        print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ (ê±´ë„ˆëœ€): {e}")
    return "\n\n".join(results)

def call_gemini_api(category_name, raw_data):
    print(f"ğŸ¤– [Gemini] '{category_name}' ë¶„ì„ ìš”ì²­ ì¤‘...")
    headers = {"Content-Type": "application/json"}
    prompt = f"""
    You are a K-Entertainment news editor.
    Raw data: {raw_data[:20000]} 

    Task: Extract 10 news items and Top 10 rankings.
    IMPORTANT: You MUST include the 'image_url' from the raw data if available.
    Output must be strict JSON without Markdown.

    Format:
    {{
      "news_updates": [
        {{ 
          "keyword": "Subject", 
          "title": "Title", 
          "summary": "Summary", 
          "link": "URL",
          "image_url": "Image URL (or null)"
        }}
      ],
      "rankings": [
        {{ "rank": 1, "title": "Name", "meta": "Info", "score": 95 }}
      ]
    }}
    """
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        full_url = f"{CURRENT_MODEL_URL}?key={GOOGLE_API_KEY}"
        response = requests.post(full_url, headers=headers, json=payload)
        if response.status_code == 200:
            try:
                text = response.json()['candidates'][0]['content']['parts'][0]['text']
                text = text.replace("```json", "").replace("```", "").strip()
                return json.loads(text)
            except Exception as e:
                print(f"   âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                return None
        else:
            print(f"   âŒ API í˜¸ì¶œ ì‹¤íŒ¨ ({response.status_code}): {response.text[:200]}")
            return None
    except Exception as e:
        print(f"   âŒ ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

def update_database(category, data):
    # ë‰´ìŠ¤ ì €ì¥
    news_list = data.get("news_updates", [])
    if news_list:
        clean_news = []
        for item in news_list:
            clean_news.append({
                "category": category,
                "keyword": item.get("keyword", category),
                "title": item.get("title", "ì œëª© ì—†ìŒ"),
                "summary": item.get("summary", ""),
                "link": item.get("link", ""),
                "image_url": item.get("image_url", ""),
                "created_at": "now()",
                "likes": 0,
                "score": 50
            })
        try:
            supabase.table("live_news").upsert(clean_news, on_conflict="category,keyword,title").execute()
            supabase.table("search_archive").upsert(clean_news, on_conflict="category,keyword,title").execute()
            print(f"   ğŸ’¾ ë‰´ìŠ¤ {len(clean_news)}ê°œ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")

    # ë­í‚¹ ì €ì¥ (live_rankings í…Œì´ë¸” ì‚¬ìš©!)
    rank_list = data.get("rankings", [])
    if rank_list:
        clean_ranks = []
        for item in rank_list:
            clean_ranks.append({
                "category": category,
                "rank": item.get("rank"),
                "title": item.get("title"),
                "meta_info": item.get("meta", ""),
                "score": item.get("score", 0),
                "updated_at": "now()"
            })
        try:
            # âœ… [ìˆ˜ì •] trending_rankings -> live_rankings ë¡œ ë³µêµ¬
            supabase.table("live_rankings").upsert(clean_ranks, on_conflict="category,rank").execute()
            print(f"   ğŸ† ë­í‚¹ ê°±ì‹  ì™„ë£Œ")
        except Exception as e:
             print(f"   âš ï¸ ë­í‚¹ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    print(f"ğŸš€ ìŠ¤í¬ë˜í¼ ì‹œì‘ (Model: {CURRENT_MODEL_URL.split('/')[-1]})")
    for category, search_keyword in CATEGORIES.items():
        raw_text = search_web(search_keyword)
        if len(raw_text) < 10: 
            print(f"âš ï¸ {category} ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€")
            continue
        data = call_gemini_api(category, raw_text)
        if data:
            update_database(category, data)
        time.sleep(3)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    main()
