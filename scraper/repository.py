from datetime import datetime, timedelta
from dateutil.parser import isoparse
from config import supabase, CATEGORY_MAP

def get_existing_links(category):
    res = supabase.table("live_news").select("link").eq("category", category).execute()
    return {item['link'] for item in res.data}

def save_news(news_list):
    if not news_list: return
    seen_links = set()
    unique_list = []
    for item in news_list:
        if item['link'] not in seen_links:
            unique_list.append(item)
            seen_links.add(item['link'])
            
    try:
        supabase.table("live_news").upsert(unique_list, on_conflict="link").execute()
        print(f"   âœ… ì‹ ê·œ {len(unique_list)}ê°œ DB ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        print(f"   âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def manage_slots(category):
    res = supabase.table("live_news").select("id", "created_at", "score").eq("category", category).execute()
    all_articles = res.data
    total_count = len(all_articles)
    
    print(f"   ğŸ“Š {category.upper()}: í˜„ì¬ {total_count}ê°œ (ëª©í‘œ: 30ê°œ)")

    if total_count > 30:
        delete_ids = []
        now = datetime.now()
        threshold = now - timedelta(hours=24)
        
        try: all_articles.sort(key=lambda x: isoparse(x['created_at']).replace(tzinfo=None))
        except: pass

        remaining_count = total_count
        
        # ì „ëµ A: 24ì‹œê°„ ì§€ë‚œ ê¸°ì‚¬ ì‚­ì œ
        for art in all_articles:
            try: art_date = isoparse(art['created_at']).replace(tzinfo=None)
            except: art_date = datetime(2000, 1, 1)

            if art_date < threshold:
                if remaining_count > 30:
                    delete_ids.append(art['id'])
                    remaining_count -= 1
                else: break

        # ì „ëµ B: ì ìˆ˜ ë‚®ì€ ìˆœ ì‚­ì œ
        if remaining_count > 30:
            survivors = [a for a in all_articles if a['id'] not in delete_ids]
            survivors.sort(key=lambda x: x['score'])
            for art in survivors:
                if remaining_count > 30:
                    delete_ids.append(art['id'])
                    remaining_count -= 1
                else: break

        if delete_ids:
            supabase.table("live_news").delete().in_("id", delete_ids).execute()
            print(f"   ğŸ§¹ ê³µê°„ í™•ë³´: {len(delete_ids)}ê°œ ì‚­ì œ ì™„ë£Œ (í˜„ì¬ {remaining_count}ê°œ ìœ ì§€).")

def archive_top_articles():
    """ìƒìœ„ ë­í¬(Top 10) ê¸°ì‚¬ ì•„ì¹´ì´ë¹™ - rank ì»¬ëŸ¼ ê¸°ì¤€"""
    print("ğŸ—„ï¸ ìƒìœ„ ë­í¬(Top 10) ê¸°ì‚¬ ì•„ì¹´ì´ë¹™ ì‹œì‘...")
    for category in CATEGORY_MAP.keys():
        # [ìˆ˜ì •] rankê°€ 10 ì´í•˜(lte)ì¸ ê²ƒë§Œ ê°€ì ¸ì˜´, ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        res = supabase.table("live_news")\
            .select("*")\
            .eq("category", category)\
            .lte("rank", 10)\
            .order("rank", desc=False)\
            .execute()
            
        top_articles = res.data
        if top_articles:
            try:
                # search_archive í…Œì´ë¸”ì— ì €ì¥
                supabase.table("search_archive").upsert(top_articles, on_conflict="link").execute()
                print(f"   ğŸ’¾ {category.upper()}: Top {len(top_articles)}ê°œ -> ì•„ì¹´ì´ë¸Œ ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"   âš ï¸ ì•„ì¹´ì´ë¸Œ ì €ì¥ ì‹¤íŒ¨ ({category}): {e}")

def update_keywords_db(keywords):
    if not keywords: return
    supabase.table("trending_keywords").delete().neq("id", 0).execute()
    
    insert_data = []
    for i, item in enumerate(keywords):
        insert_data.append({
            "keyword": item.get('keyword'),
            "count": item.get('count', 0),
            "rank": item.get('rank', i + 1),
            "updated_at": datetime.now().isoformat()
        })
    
    if insert_data:
        supabase.table("trending_keywords").insert(insert_data).execute()
        print("   âœ… í‚¤ì›Œë“œ ë­í‚¹ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ.")

def get_recent_titles(limit=100):
    res = supabase.table("live_news").select("title").order("created_at", desc=True).limit(limit).execute()
    return [item['title'] for item in res.data]
