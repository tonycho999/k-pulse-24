from datetime import datetime, timedelta
from dateutil.parser import isoparse
from config import supabase, CATEGORY_MAP

def get_existing_links(category):
    # ì¤‘ë³µ ì²´í¬ë¥¼ ìœ„í•´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ë§í¬ ì¡°íšŒ
    res = supabase.table("live_news").select("link").eq("category", category).execute()
    return {item['link'] for item in res.data}

def save_news(news_list):
    """
    ë‰´ìŠ¤ ì €ì¥: ì¤‘ë³µ ì œê±° ë° 4.0ì  ë¯¸ë§Œ ê¸°ì‚¬ í•„í„°ë§
    """
    if not news_list: return
    
    seen_links = set()
    unique_list = []
    
    for item in news_list:
        # [ê·œì¹™ 3] 4ì  ë¯¸ë§Œ ê¸°ì‚¬ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ
        if item.get('score', 0) < 4.0:
            continue

        if item['link'] not in seen_links:
            unique_list.append(item)
            seen_links.add(item['link'])
            
    if not unique_list:
        print("   â„¹ï¸ ì €ì¥í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ ì¤‘ë³µì´ê±°ë‚˜ 4ì  ë¯¸ë§Œ).")
        return

    try:
        supabase.table("live_news").upsert(unique_list, on_conflict="link").execute()
        print(f"   âœ… ì‹ ê·œ {len(unique_list)}ê°œ DB ì €ì¥ ì™„ë£Œ (4ì  ì´ìƒ).")
    except Exception as e:
        print(f"   âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")

def manage_slots(category):
    """
    [ê·œì¹™ 5, 6, 7] 30ê°œ ìŠ¬ë¡¯ ìœ ì§€ ê´€ë¦¬ ë¡œì§ (ë­í‚¹ ì—…ë°ì´íŠ¸ í¬í•¨)
    """
    # 1. í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜´
    res = supabase.table("live_news").select("*").eq("category", category).execute()
    all_articles = res.data
    total_count = len(all_articles)
    
    print(f"   ğŸ“Š {category.upper()}: í˜„ì¬ {total_count}ê°œ (ëª©í‘œ: 30ê°œ)")

    # 30ê°œ ì´í•˜ë¼ë©´ ì‚­ì œ ë¡œì§ ë¶ˆí•„ìš” -> ë°”ë¡œ ë­í‚¹ë§Œ ì—…ë°ì´íŠ¸
    if total_count <= 30:
        _update_rankings(all_articles)
        return

    # --- ì‚­ì œ ë¡œì§ ì‹œì‘ ---
    delete_ids = []
    now = datetime.now()
    threshold = now - timedelta(hours=24) # 24ì‹œê°„ ê¸°ì¤€
    
    # ê¸°ì‚¬ ì •ë ¬: ë‚ ì§œìˆœ (ì˜¤ë˜ëœ ê²ƒ ì‹ë³„ìš©)
    try: 
        all_articles.sort(key=lambda x: isoparse(x['created_at']).replace(tzinfo=None))
    except: pass

    remaining_count = total_count
    
    # [ê·œì¹™ 5] 24ì‹œê°„ ì§€ë‚œ ê¸°ì‚¬ ìš°ì„  ì‚­ì œ (ë‹¨, 30ê°œ ë  ë•Œê¹Œì§€ë§Œ)
    for art in all_articles:
        if remaining_count <= 30: break # 30ê°œ ë„ë‹¬ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
        
        try: art_date = isoparse(art['created_at']).replace(tzinfo=None)
        except: art_date = datetime(2000, 1, 1)

        if art_date < threshold:
            delete_ids.append(art['id'])
            remaining_count -= 1

    # [ê·œì¹™ 6] ê·¸ë˜ë„ 30ê°œê°€ ë„˜ìœ¼ë©´ ì ìˆ˜ ë‚®ì€ ìˆœ ì‚­ì œ
    if remaining_count > 30:
        survivors = [a for a in all_articles if a['id'] not in delete_ids]
        # ì ìˆ˜ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (ë‚®ì€ ì ìˆ˜ë¶€í„° ì‚­ì œ)
        survivors.sort(key=lambda x: x.get('score', 0))
        
        for art in survivors:
            if remaining_count <= 30: break
            delete_ids.append(art['id'])
            remaining_count -= 1

    # ì‹¤ì œ ì‚­ì œ ì‹¤í–‰
    if delete_ids:
        supabase.table("live_news").delete().in_("id", delete_ids).execute()
        print(f"   ğŸ§¹ ê³µê°„ í™•ë³´: {len(delete_ids)}ê°œ ì‚­ì œ ì™„ë£Œ (í˜„ì¬ {remaining_count}ê°œ ìœ ì§€).")
    
    # [ê·œì¹™ 7] ì‚­ì œ ì™„ë£Œ í›„ ë‚¨ì€ ê¸°ì‚¬ë“¤ì— ëŒ€í•´ Rank ì¬ì‚°ì • ë° ì—…ë°ì´íŠ¸
    final_survivors = [a for a in all_articles if a['id'] not in delete_ids]
    _update_rankings(final_survivors)

def _update_rankings(articles):
    """
    ë‚¨ì€ ê¸°ì‚¬ë“¤ì„ ì ìˆ˜ìˆœ(ë‚´ë¦¼ì°¨ìˆœ)ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ rank(1~30) ì—…ë°ì´íŠ¸
    """
    if not articles: return

    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
    articles.sort(key=lambda x: x.get('score', 0), reverse=True)
    
    updates = []
    for i, art in enumerate(articles):
        new_rank = i + 1
        if art.get('rank') != new_rank:
            updates.append({"id": art['id'], "rank": new_rank})
            
    if updates:
        try:
            supabase.table("live_news").upsert(updates).execute()
            print(f"   ğŸ”„ {len(updates)}ê°œ ê¸°ì‚¬ ë­í‚¹(Rank) ì¬ì •ë ¬ ì™„ë£Œ.")
        except Exception as e:
            print(f"   âš ï¸ ë­í‚¹ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def archive_top_articles():
    """ìƒìœ„ ë­í¬(Top 10) ê¸°ì‚¬ ì•„ì¹´ì´ë¹™"""
    print("ğŸ—„ï¸ ìƒìœ„ ë­í¬(Top 10) ê¸°ì‚¬ ì•„ì¹´ì´ë¹™ ì‹œì‘...")
    
    for category in CATEGORY_MAP.keys():
        # [í•µì‹¬ ìˆ˜ì •] rankê°€ 0ë³´ë‹¤ í¬ê³  10 ì´í•˜ì¸ ê²ƒ ì¡°íšŒ
        res = supabase.table("live_news")\
            .select("*")\
            .eq("category", category)\
            .lte("rank", 10)\
            .gt("rank", 0)\
            .order("rank", desc=False)\
            .execute()
            
        top_articles = res.data
        if top_articles:
            try:
                # search_archive í…Œì´ë¸”ì— ì €ì¥í•  ë°ì´í„° ë§¤í•‘
                archive_data = []
                for art in top_articles:
                    archive_data.append({
                        "created_at": art['created_at'],
                        "category": art['category'],
                        "title": art['title'],
                        "summary": art['summary'],
                        "image_url": art['image_url'],
                        "original_link": art['link'],  # live_newsì˜ linkë¥¼ archiveì˜ original_linkë¡œ ì €ì¥
                        "score": art['score'],
                        "rank": art['rank']
                    })
                
                # ë§í¬(original_link) ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ë°©ì§€(upsert)
                supabase.table("search_archive").upsert(archive_data, on_conflict="original_link").execute()
                print(f"   ğŸ’¾ {category.upper()}: Top {len(archive_data)}ê°œ -> ì•„ì¹´ì´ë¸Œ ì €ì¥ ì™„ë£Œ.")
            except Exception as e:
                print(f"   âš ï¸ ì•„ì¹´ì´ë¸Œ ì €ì¥ ì‹¤íŒ¨ ({category}): {e}")

def update_keywords_db(keywords):
    if not keywords: return
    try:
        supabase.table("trending_keywords").delete().neq("id", 0).execute()
    except: pass 
    
    insert_data = []
    for i, item in enumerate(keywords):
        insert_data.append({
            "keyword": item.get('keyword'),
            "count": item.get('count', 0),
            "rank": item.get('rank', i + 1),
            "updated_at": datetime.now().isoformat()
        })
    
    if insert_data:
        try:
            supabase.table("trending_keywords").insert(insert_data).execute()
            print("   âœ… í‚¤ì›Œë“œ ë­í‚¹ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ.")
        except Exception as e:
            print(f"   âš ï¸ í‚¤ì›Œë“œ ì €ì¥ ì‹¤íŒ¨: {e}")

def get_recent_titles(limit=100):
    res = supabase.table("live_news").select("title").order("created_at", desc=True).limit(limit).execute()
    return [item['title'] for item in res.data]
