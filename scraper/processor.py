# scraper/processor.py
import time
from datetime import datetime
import config
import naver_api
import gemini_api
import database

def run_category_process(category):
    print(f"\nğŸš€ [Processing] Category: {category}")

    # 1. [ìˆ˜ì •ë¨] 3ê°œì˜ í‚¤ì›Œë“œë¡œ ê°ê° ê²€ìƒ‰ í›„ ê²°ê³¼ í•©ì¹˜ê¸°
    queries = config.SEARCH_QUERIES.get(category, [])
    all_raw_items = []
    seen_links = set() # ì¤‘ë³µ ê¸°ì‚¬ ì œê±°ìš©

    print(f"   1ï¸âƒ£ Fetching news with 3 queries...")
    
    for q in queries:
        print(f"      - Query: '{q}'")
        # ê° ì¿¼ë¦¬ë‹¹ 20ê°œì”© ìˆ˜ì§‘ (ì´ 60ê°œ í™•ë³´)
        items = naver_api.search_news_api(q, display=20)
        
        for item in items:
            # ì¤‘ë³µ ì œê±° (ë§í¬ ê¸°ì¤€)
            if item['link'] not in seen_links:
                seen_links.add(item['link'])
                all_raw_items.append(item)
        
        time.sleep(0.5) # API ë§¤ë„ˆ í˜¸ì¶œ

    if not all_raw_items:
        print("   âŒ [Stop] No items found from all queries.")
        return

    print(f"      âœ… Total collected articles: {len(all_raw_items)}")
    
    # AIì—ê²Œ ë³´ë‚¼ ê¸°ì‚¬ ì œëª© ë¦¬ìŠ¤íŠ¸ ìƒì„±
    titles = "\n".join([f"- {item['title']}" for item in all_raw_items])

    # 2. ë­í‚¹ & ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ
    print("   2ï¸âƒ£ Extracting Keywords (Subject vs Person)...")

    # ì¹´í…Œê³ ë¦¬ë³„ ê·œì¹™ (ì§€ë‚œë²ˆê³¼ ë™ì¼)
    if category == "K-Pop":
        rule = """
        - Target(DB): **SONG TITLE** (e.g., 'Super Shy').
        - Search: **ARTIST/GROUP NAME** (e.g., 'NewJeans').
        """
    elif category == "K-Drama":
        rule = """
        - Target(DB): **DRAMA TITLE** (e.g., 'Squid Game').
        - Search: **MAIN ACTOR NAME** (e.g., 'Lee Jung-jae').
        """
    elif category == "K-Movie":
        rule = """
        - Target(DB): **MOVIE TITLE** (e.g., 'Exhuma').
        - Search: **MAIN ACTOR NAME** (e.g., 'Choi Min-sik').
        """
    elif category == "K-Entertain":
        rule = """
        - Target(DB): **SHOW TITLE** (e.g., 'Running Man').
        - Search: **CAST MEMBER NAME** (e.g., 'Yoo Jae-suk').
        """
    else: # K-Culture
        rule = """
        - Target(DB): Place, Food, or Tradition Name (English).
        - Search: Korean Name of the Place/Food.
        - **CRITICAL**: EXCLUDE ALL IDOLS/KPOP GROUPS. Focus only on Travel/Food.
        """

    rank_prompt = f"""
    [Task]
    Analyze these {len(all_raw_items)} news titles about {category}.
    Extract Top 10 trends following these STRICT rules:
    {rule}

    [Output JSON]
    {{ 
      "rankings": [ 
        {{ 
          "rank": 1, 
          "display_title_en": "English Title for DB", 
          "search_keyword_kr": "Korean Name for Searching", 
          "meta": "Short Info", 
          "score": 95 
        }} 
      ] 
    }}
    """
    
    rank_res = gemini_api.ask_gemini(rank_prompt)
    if not rank_res: return

    rankings = rank_res.get("rankings", [])[:10]
    
    # ë­í‚¹ ì €ì¥
    db_rankings = []
    for item in rankings:
        db_rankings.append({
            "category": category,
            "rank": item.get("rank"),
            "title": item.get("display_title_en"),
            "meta_info": item.get("meta", ""),
            "score": item.get("score", 0),
            "updated_at": datetime.now().isoformat()
        })
    database.save_rankings_to_db(db_rankings)

    # 3. íƒ€ê²Ÿ ì„ ì • (ë„ë°° ë°©ì§€)
    print("   3ï¸âƒ£ Selecting Target...")
    target_display = ""
    target_search = ""
    
    for item in rankings:
        d_title = item.get("display_title_en")
        s_word = item.get("search_keyword_kr")
        
        if database.is_keyword_used_recently(category, d_title, hours=4):
            print(f"      - Skip '{d_title}' (Cooldown)")
        else:
            print(f"      - Selected: '{d_title}' (Search: {s_word})")
            target_display = d_title
            target_search = s_word
            break
    
    if not target_display and rankings:
        target_display = rankings[0].get("display_title_en")
        target_search = rankings[0].get("search_keyword_kr")

    if not target_display: return

    # 4. ì •ë°€ ê²€ìƒ‰
    print(f"   4ï¸âƒ£ Searching Naver for '{target_search}'...")
    target_items = naver_api.search_news_api(target_search, display=5)
    
    full_texts = []
    target_link = ""
    target_image = ""

    for item in target_items:
        link = item['link']
        crawled = naver_api.crawl_article(link)
        if crawled['text']:
            full_texts.append(crawled['text'])
            if not target_image: target_image = crawled['image']
            if not target_link: target_link = link
        else:
            full_texts.append(item['description'])
            if not target_link: target_link = link

    if not full_texts: return

    # 5. ìš”ì•½ ì‘ì„± (ì˜ì–´)
    print(f"   5ï¸âƒ£ Summarizing '{target_display}'...")
    summary_prompt = f"""
    [Context]
    Category: {category}
    Main Subject: {target_display}
    Person involved: {target_search}
    
    [Source Articles (Korean)]
    {str(full_texts)[:6000]}

    [Task]
    Write a news summary in **ENGLISH**.
    - Title: Must be about '{target_display}' (Song/Drama/Place).
    - Summary: Focus on why '{target_search}' is in the news regarding '{target_display}'.

    [Output JSON]
    {{ "title": "English Title", "summary": "English Summary..." }}
    """
    
    sum_res = gemini_api.ask_gemini(summary_prompt)
    
    if sum_res:
        news_item = {
            "category": category,
            "keyword": target_display,
            "title": sum_res.get("title", f"News about {target_display}"),
            "summary": sum_res.get("summary", ""),
            "link": target_link,
            "image_url": target_image,
            "score": 100,
            "created_at": datetime.now().isoformat(),
            "likes": 0
        }
        
        database.save_news_to_live([news_item])
        database.save_news_to_archive([news_item])
        database.cleanup_old_data(category, config.MAX_ITEMS_PER_CATEGORY)
        print("   ğŸ‰ SUCCESS!")
