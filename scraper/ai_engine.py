import json
import re
from config import groq_client

def get_best_model():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹ /ê³ ì„±ëŠ¥ AI ëª¨ë¸ ìë™ ì„ íƒ (ë²„ì „ ìˆ«ì ê¸°ë°˜)"""
    try:
        models_raw = groq_client.models.list()
        available_models = [m.id for m in models_raw.data]
        
        def model_scorer(model_id):
            score = 0
            mid = model_id.lower()
            
            # 1. ë²„ì „ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: llama-3.3 -> 3.3)
            version_match = re.search(r'(\d+\.?\d*)', mid)
            if version_match:
                try:
                    version = float(version_match.group(1))
                    score += version * 1000  # ë²„ì „ì´ ë†’ì„ìˆ˜ë¡ ìµœìš°ì„ 
                except: pass

            # 2. ëª¨ë¸ í¬ê¸° ê°€ì‚°ì 
            if "70b" in mid: score += 500
            elif "8b" in mid: score += 100
            
            # 3. ëª¨ë¸ ê³„ì—´ ê°€ì‚°ì 
            if "llama" in mid: score += 50
            elif "mixtral" in mid: score += 40
            
            return score

        available_models.sort(key=model_scorer, reverse=True)
        print(f"ğŸ¤– AI ëª¨ë¸ ìš°ì„ ìˆœìœ„: {available_models[:3]}")
        return available_models
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ì¡°íšŒ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        return ["llama-3.3-70b-versatile", "mixtral-8x7b-32768"]

MODELS_TO_TRY = get_best_model()

def ai_category_editor(category, news_batch):
    """ë‰´ìŠ¤ ê¸°ì‚¬ ì„ ë³„, ìš”ì•½ ë° ì ìˆ˜ ë¶€ì—¬"""
    if not news_batch: return []
    
    # ìµœëŒ€í•œ ë§ì€ í›„ë³´êµ°ì„ AIì—ê²Œ ì „ë‹¬
    limited_batch = news_batch[:60] 
    
    raw_text = ""
    for i, n in enumerate(limited_batch):
        clean_desc = n['description'].replace('<b>', '').replace('</b>', '').replace('&quot;', '"')
        raw_text += f"[{i}] Title: {n['title']} / Link: {n['link']} / Context: {clean_desc}\n"
    
    # [ìˆ˜ì •] ì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜ ì •ì±… ì°¨ë“± ì ìš© (ì´ì›í™” ì „ëµ)
    if category == 'k-culture':
        # [ì „ëµ 1] ë§ˆì´ë„ˆ ì¹´í…Œê³ ë¦¬: ê¸°ì‚¬ëŸ‰ í™•ë³´ë¥¼ ìœ„í•´ 'í›„í•œ ì ìˆ˜' (Generous)
        score_instruction = """
        This is 'K-Culture' (Food, Fashion, Travel). Since news volume is typically low:
        - Be GENEROUS with scoring.
        - If the article is relevant to Korea, give at least 6.0.
        - If it's interesting or informative, give 7.5~8.5.
        - Only give < 5.0 if it is completely irrelevant or spam.
        """
    else:
        # [ì „ëµ 2] ë©”ì¸ ì¹´í…Œê³ ë¦¬: í€„ë¦¬í‹° í™•ë³´ë¥¼ ìœ„í•´ 'ì—„ê²©í•œ ê¸°ì¤€' (Strict/Objective)
        score_instruction = """
        This is MAIN Entertainment news (K-Pop, Drama, Actors). Volume is high:
        - Be STRICT/OBJECTIVE with scoring.
        - Standard/Routine news (e.g., simple schedule updates) -> 5.0~6.5
        - Good news (e.g., new release, casting) -> 7.0~8.5
        - HUGE Breaking news (e.g., global awards, dating reveal) -> 9.0~10.0
        """

    prompt = f"""
    Task: Select the best 30 news items for '{category}'.
    
    [Selection Rules]
    1. Score >= 4.0: MUST include articles with score 4.0 or higher.
    2. Diversity: If multiple articles cover the same topic, select ones with different angles or sources.
    3. Deduplication: Do not select nearly identical articles.

    [Output Constraints]
    1. English Title: Translate naturally.
    2. English Summary: 
       - Summarize to 40-50% of original length.
       - Create a rich, narrative paragraph (5-8 sentences). NO bullet points.
    3. AI Score (0.0-10.0): 
       - {score_instruction}
    4. Return JSON format strictly.

    News List:
    {raw_text}

    Output JSON Format:
    {{
        "articles": [
            {{ "original_index": 0, "eng_title": "...", "summary": "...", "score": 8.5 }}
        ]
    }}
    """
    
    for model in MODELS_TO_TRY:
        try:
            res = groq_client.chat.completions.create(
                messages=[{"role": "system", "content": f"You are a generic K-Enter Journalist for {category}."},
                          {"role": "user", "content": prompt}], 
                model=model, 
                response_format={"type": "json_object"}
            )
            data = json.loads(res.choices[0].message.content)
            articles = data.get('articles', [])
            if articles: return articles
        except Exception as e:
            print(f"      âš ï¸ {model} ì˜¤ë¥˜. ë‹¤ìŒ ëª¨ë¸ ì‹œë„.")
            continue
    return []

def ai_analyze_keywords(titles):
    """ê¸°ì‚¬ ì œëª© ê¸°ë°˜ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    titles_text = "\n".join([f"- {t}" for t in titles])
    
    # [ìˆ˜ì •] êµ¬ì²´ì  ì˜ˆì‹œ ì‚­ì œ í›„ ì¼ë°˜ì  í…œí”Œë¦¿ ì ìš©
    prompt = f"""
    Analyze the following K-Entertainment news titles and identify the TOP 10 most trending keywords.
    [Rules]
    1. Extract specific Entities: Person Name, Group Name, Drama/Movie Title.
    2. Merge related concepts: "BTS Jin" instead of "Jin".
    3. EXCLUDE generic words: Variety, Actor, K-pop, Review, Netizens, Update, Official.
    4. Return JSON format with 'keyword' and estimated 'count' (1-100).
    
    [Titles]
    {titles_text}
    
    [Output Format JSON]
    {{
        "keywords": [
            {{ "keyword": "Most Mentioned Keyword", "count": 95, "rank": 1 }},
            {{ "keyword": "Second Keyword", "count": 80, "rank": 2 }}
        ]
    }}
    """
    
    for model in MODELS_TO_TRY:
        try:
            res = groq_client.chat.completions.create(
                messages=[{"role": "system", "content": "You are a K-Trend Analyst."},
                          {"role": "user", "content": prompt}], 
                model=model, response_format={"type": "json_object"}
            )
            result = json.loads(res.choices[0].message.content)
            keywords = result.get('keywords', [])
            if keywords: return keywords
        except Exception as e:
            print(f"      âš ï¸ {model} ë¶„ì„ ì‹¤íŒ¨: {e}")
            continue
    return []
