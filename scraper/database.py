# scraper/database.py
import os
from supabase import create_client, Client
from dotenv import load_dotenv
# ìƒìœ„ í´ë”ì˜ .env ë¡œë“œ
load_dotenv(os.path.join(os.path.dirname(__file__), '../.env'))

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

supabase: Client = None
try:
    if SUPABASE_URL and SUPABASE_KEY:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    else:
        print("ğŸš¨ Supabase credentials missing in .env")
except Exception as e:
    print(f"ğŸš¨ Supabase Connection Error: {e}")

def save_news_to_db(data_list):
    """live_news í…Œì´ë¸”ì— ì €ì¥ (ì»¬ëŸ¼: category, keyword, title, summary, link, image_url, score)"""
    if not supabase or not data_list: return

    try:
        # bulk insert (upsert)
        result = supabase.table("live_news").upsert(data_list).execute()
        print(f"   ğŸ’¾ Saved {len(data_list)} articles to 'live_news'.")
    except Exception as e:
        print(f"   âš ï¸ DB Save Error (live_news): {e}")

def save_rankings_to_db(rank_list):
    """live_rankings í…Œì´ë¸”ì— ì €ì¥ (ì»¬ëŸ¼: category, rank, title, meta_info, score)"""
    if not supabase or not rank_list: return

    try:
        result = supabase.table("live_rankings").upsert(rank_list).execute()
        print(f"   ğŸ† Saved rankings to 'live_rankings'.")
    except Exception as e:
        print(f"   âš ï¸ DB Save Error (live_rankings): {e}")

def cleanup_old_data(category, table_name="live_news", max_limit=30):
    """ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ"""
    if not supabase: return

    try:
        # 1. í˜„ì¬ ê°œìˆ˜ í™•ì¸
        res = supabase.table(table_name).select("id", count="exact").eq("category", category).execute()
        count = res.count

        if count > max_limit:
            # 2. ì§€ì›Œì•¼ í•  ê°œìˆ˜ ê³„ì‚°
            items_to_remove = count - max_limit
            
            # 3. ì˜¤ë˜ëœ ìˆœìœ¼ë¡œ ID ì¡°íšŒ (created_at ê¸°ì¤€)
            # live_rankingsëŠ” updated_at, live_newsëŠ” created_at ì‚¬ìš©
            sort_col = "updated_at" if table_name == "live_rankings" else "created_at"
            
            old_rows = supabase.table(table_name)\
                .select("id")\
                .eq("category", category)\
                .order(sort_col, desc=False)\
                .limit(items_to_remove)\
                .execute()
            
            ids = [row['id'] for row in old_rows.data]
            
            if ids:
                supabase.table(table_name).delete().in_("id", ids).execute()
                print(f"   ğŸ§¹ Cleaned up {len(ids)} old items from '{table_name}'.")
                
    except Exception as e:
        print(f"   âš ï¸ Cleanup Error: {e}")
